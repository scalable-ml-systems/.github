## Scalable ML Systems
Production‑grade ML infrastructure shaped by real problems and real workloads.

What I Build
- LLM inference runtimes with multi‑model routing, continuous batching, and strict latency SLOs
- GPU‑accelerated serving platforms using Triton, vLLM, and Ray
- Event‑driven cognitive runtimes orchestrating multimodal inference through Kafka workflows
- Multi‑cloud GPU infrastructure (AWS, Azure, GCP) with Terraform + Kubernetes
- Deep observability stacks (OpenTelemetry, Prometheus, Grafana) for token‑level and GPU‑level metrics
- Secure, reproducible AI pipelines with strong boundaries, IAM, mTLS, and containerized deployments

I build systems that startups can run in production — not prototypes.

#### Built by Nancy Bethala‑Frounjian | AI Infrastructure Engineer

#### Community
- Technical notes: [StackBytes](https://stackbytes.beehiiv.com/)
- Portfolio & labs: [nbethala](https://github.com/nbethala)
- Contact: nfrounjian@gmail.com

