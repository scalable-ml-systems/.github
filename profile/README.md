## Scalable ML Systems
Production‑grade ML infrastructure shaped by real problems and real workloads.

Core Focus
 - High‑throughput inference: multi‑model routing, continuous batching, strict latency SLOs
 - GPU serving: Triton, vLLM, Ray
 - Cognitive runtimes: event‑driven, multimodal workflows with Kafka
 - Cloud‑native AI: multi‑cloud GPU infrastructure on AWS, Azure, GCP
 - Deep observability: token‑level + GPU‑level insights with OTel, Prometheus, Grafana
 - Security & reproducibility: IAM, mTLS, containerized deployments
   
I build systems that startups can run in production — not prototypes.

#### Built by Nancy Bethala‑Frounjian | AI Infrastructure Engineer

#### Community
- Technical notes: [StackBytes](https://stackbytes.beehiiv.com/)
- Portfolio & labs: [nbethala](https://github.com/nbethala)
- Contact: nfrounjian@gmail.com

